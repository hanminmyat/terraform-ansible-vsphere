---
- hosts: spark-cluster
  become: true
  tasks:
    - name: Install Java (OpenJDK)
      yum:
        name: java-1.8.0-openjdk
        state: present

    - name: Download and extract Apache Spark
      get_url:
        url: "https://downloads.apache.org/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz"
        dest: "/opt/"
      delegate_to: localhost

    - name: Extract Spark archive
      ansible.builtin.unarchive:
        src: "/opt/spark-3.2.0-bin-hadoop3.2.tgz"
        dest: "/opt/"
      delegate_to: localhost

    - name: Create Spark directories
      file:
        path: "{{ item }}"
        state: directory
        mode: 0755
      loop:
        - "/opt/spark-3.2.0-bin-hadoop3.2/logs"
        - "/opt/spark-3.2.0-bin-hadoop3.2/work"

    - name: Configure Spark environment
      template:
        src: "spark-env.sh.j2"
        dest: "/opt/spark-3.2.0-bin-hadoop3.2/conf/spark-env.sh"

    - name: Start Spark Master
      command: "/opt/spark-3.2.0-bin-hadoop3.2/sbin/start-master.sh"
      environment:
        SPARK_HOME: "/opt/spark-3.2.0-bin-hadoop3.2"
      register: spark_master_output
      ignore_errors: true

    - name: Print Spark Master Web UI URL
      debug:
        msg: "Spark Master Web UI: http://{{ ansible_host }}:8080"
      when: spark_master_output.rc == 0

    - name: Start Spark Worker
      command: "/opt/spark-3.2.0-bin-hadoop3.2/sbin/start-worker.sh spark://{{ spark_master_url.stdout_lines[0] }}"
      environment:
        SPARK_HOME: "/opt/spark-3.2.0-bin-hadoop3.2"
      loop: "{{ groups['spark-cluster'] }}"
